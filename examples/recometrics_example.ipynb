{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating recommender systems\n",
    "\n",
    "This vignette is an introduction to the Python package\n",
    "[recometrics](https://www.github.com/david-cortes/recometrics)\n",
    "for evaluating recommender systems built with implicit-feedback data, assuming\n",
    "that the recommendation models are based on low-rank matrix factorization\n",
    "(example such packages:\n",
    "[implicit](https://github.com/benfred/implicit),\n",
    "[lightfm](https://github.com/lyst/lightfm),\n",
    "[cmfrec](https://github.com/david-cortes/cmfrec),\n",
    "among many others), or assuming that it is possible to compute a user-item\n",
    "score as a dot product of user and item factors/components/attributes.\n",
    "\n",
    "### Implicit-feedback data\n",
    "\n",
    "Historically, many models for recommender systems were designed by approaching the\n",
    "problem as regression or rating prediction, by taking as input a matrix\n",
    "$\\mathbf{X}_{ui}$ denoting user likes and dislikes of items in a scale\n",
    "(e.g. users giving a 1-to-5 star rating to different movies), and evaluating such\n",
    "models by seeing how well they predict these ratings on hold-out data.\n",
    "\n",
    "In many cases, it is impossible or very expensive to obtain such data, but one\n",
    "has instead so called \"implicit-feedback\" records: that is, observed logs of user\n",
    "interactions with items (e.g. number of times that a user played each\n",
    "song in a music service), which do not signal dislikes in the same way as a\n",
    "1-star rating would, but can still be used for building and evaluating\n",
    "recommender systems.\n",
    "\n",
    "In the latter case, the problem is approached more as ranking or classification\n",
    "instead of regression, with the models being evaluated not by how well they\n",
    "perform at predicting ratings, but by how good they are at scoring the observed\n",
    "interactions higher than the non-observed interactions for each user, using\n",
    "metrics more typical of information retrieval.\n",
    "\n",
    "Generating a ranked list of items for each user according to their predicted\n",
    "score and comparing such lists against hold-out data can nevertheless be very\n",
    "slow (might even be slower than fitting the model itself), and this is where\n",
    "`recometrics` comes in: it provides efficient routines for calculating many\n",
    "implicit-feedback recommendation quality metrics, which exploit multi-threading,\n",
    "SIMD instructions, and efficient sorted search procedures.\n",
    "\n",
    "### Matrix factorization models\n",
    "\n",
    "The perhaps most common approach towards building a recommendation model is by\n",
    "trying to approximate the matrix $\\mathbf{X}_{mn}$ as the product of two\n",
    "lower-dimensional matrices $\\mathbf{A}_{mk}$ and $\\mathbf{B}_{nk}$ (with\n",
    "$k \\ll m$ and $k \\ll n$), representing latent user and item factors/components,\n",
    "respectively (which are the model parameters to estimate) - i.e.\n",
    "$$\n",
    "\\mathbf{X} \\approx \\mathbf{A} \\mathbf{B}^T\n",
    "$$\n",
    "In the explicit-feedback setting (e.g. movie ratings), this is typically done by\n",
    "trying to minimize squared errors with respect to the **observed** entries in\n",
    "$\\mathbf{X}$, while in implicit-feedback settings this is typically done by turning the\n",
    "$\\mathbf{X}$ matrix into a binary matrix which has a one if the observation is observed\n",
    "and a zero if not, using the actual values (e.g. number of times that a song was played)\n",
    "instead as weights for the positive entries, thereby looking at **all** entries rather\n",
    "than just the observed (non-zero) values - e.g.:\n",
    "$$\n",
    "\\min_{\\mathbf{A}, \\mathbf{B}} \\sum_{u=1}^{m} \\sum_{i=1}^{n} x_{ui} (I_{x_{ui}>0} - \\mathbf{a}_u \\cdot \\mathbf{b}_i)^2\n",
    "$$\n",
    "\n",
    "The recommendations for a given user are then produced by calculating the full products\n",
    "between that user vector $\\mathbf{a}_u$ and the $\\mathbf{B}$ matrix, sorting these\n",
    "predicted scores in descending order.\n",
    "\n",
    "For a better overview of implicit-feedback matrix factorization, see the paper\n",
    "_Hu, Yifan, Yehuda Koren, and Chris Volinsky. \"Collaborative filtering for implicit feedback datasets.\" 2008 Eighth IEEE International Conference on Data Mining. Ieee, 2008._\n",
    "\n",
    "## Evaluating recommendation models\n",
    "\n",
    "Such matrix factorization models are commonly evaluated by setting aside a small amount\n",
    "of users as hold-out for evaluation, fitting a model to all the remaining users and\n",
    "items. Then, from the evaluation users, a fraction of their interactions data is set as a\n",
    "hold-out test set, while their latent factors are computed using the rest of the data\n",
    "and the previously fitted model from the other users.\n",
    "\n",
    "Then, top-K recommendations for each user are produced, discarding the non-hold-out\n",
    "items with which their latent factors were just determined, and these top-K lists are\n",
    "compared against the hold-out test items, seeing how well they do at ranking them near\n",
    "the top vs. how they rank the remainder of the items.\n",
    "\n",
    "** *\n",
    "\n",
    "This package can be used to calculate many recommendation quality metrics given the\n",
    "user and item factors and the train-test data split that was used, including:\n",
    "\n",
    "* **P\\@K** (\"precision-at-k\"): this is the most intuitive metric. It calculates the\n",
    "proportion of the top-K recommendations that include items from the test set for\n",
    "a given user - i.e.\n",
    "$$\n",
    "P@K = \\frac{1}{k} \\sum_{i=1}^k\n",
    "\\begin{cases}\n",
    "    1, & r_i \\in \\mathcal{T}\\\\\n",
    "    0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "Where $r_i$ is the item ranked at position $i$ by the model (sorting the predicted\n",
    "scores in descending order, after excluding the items in the training data for that \n",
    "user), and $\\mathcal{T}$ is the set of items that are in the test set for that user.\n",
    "\n",
    "    Note that some papers and libraries define $P@K$ differently, see the second\n",
    "version below.\n",
    "\n",
    "* **TP\\@K** (truncated $P@K$): same calculation as $P@K$, but will instead divide by\n",
    "the minimum between $k$ and the number of test items:\n",
    "$$\n",
    "TP@K = \\frac{1}{\\min\\{k, |\\mathcal{T}|\\}} \\sum_{i=1}^k\n",
    "\\begin{cases}\n",
    "    1, & r_i \\in \\mathcal{T}\\\\\n",
    "    0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "    The \"truncated\" prefix is a non-standard nomenclature introduced here to\n",
    "differentiate it from the other $P@K$ metric.\n",
    "\n",
    "* **R\\@K** (\"recall-at-k\"): while $P@K$ offers an intuitive metric that captures what\n",
    "a recommender system aims at being good at, it does not capture the fact that,\n",
    "the more test items there are, the higher the chances that they will be included in the\n",
    "top-K recommendations. Recall instead looks at what proportion of the test\n",
    "items would have been retrieved with the top-K recommended list:\n",
    "$$\n",
    "R@K = \\frac{1}{|\\mathcal{T}|} \\sum_{i=1}^k\n",
    "\\begin{cases}\n",
    "    1, & r_i \\in \\mathcal{T}\\\\\n",
    "    0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "* **AP\\@K** (\"average precision-at-k\"): precision and recall look at all the items\n",
    "in the top-K equally, whereas one might want to take into account also the ranking\n",
    "within this top-K list, for which this metric comes in handy.\n",
    "\"Average Precision\" tries to reflect the precisions that would be obtained at\n",
    "different recalls:\n",
    "$$\n",
    "AP@K = \\frac{1}{|\\mathcal{T}|} \\sum_{i=1}^k\n",
    "\\begin{cases}\n",
    "    P@i, & r_i \\in \\mathcal{T}\\\\\n",
    "    0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "$AP@K$ is a metric which to some degree considers precision, recall, and rank within\n",
    "top-K. Intuitively, it tries to approximate the are under a precision-recall tradeoff\n",
    "curve. Its average across users is typically called \"MAP\\@K\" or \"Mean Average Precision\".\n",
    "\n",
    "    **Important:** many authors define $AP@K$ differently, such as dividing by the minimum\n",
    "between $k$ and $|\\mathcal{T}|$ instead, or as the average for P\\@1..P\\@K (either as-is\n",
    "or stopping the calculation after already retrieving all test items).\n",
    "See below for the other version.\n",
    "\n",
    "* **TAP\\@K** (truncated $AP@K$): a truncated version of the\n",
    "$AP@K$ metric, which will instead divide it by the minimum between $k$ and the\n",
    "number of test items. Just like for $TP@K$, the \"truncated\" prefix is a non-standard\n",
    "nomenclature used here to differentiate it from the other more typical $AP@K$.\n",
    "\n",
    "* **NDCG\\@K** (\"normalized discounted cumulative gain at k\"): while the earlier metrics\n",
    "look at just the presence of an item in the test set, these items might not all be as\n",
    "good, with some of them having higher observed values than others. NDCG aims at\n",
    "judging these values, but discounted according to the rank in the top-K list. First\n",
    "it calculates the unstandardized discounted cumulative gain:\n",
    "$$\n",
    "DCG@K = \\sum_{i=1}^{k} \\frac{C_{r_i}}{log_2 (1+i)}\n",
    "$$\n",
    "Where $C_{r_i}$ indicates the observed interaction value in the test data for item\n",
    "$r_i$, and is zero if the item was not in the test data. The DCG\\@K metric is then\n",
    "standardized by dividing it by the maximum achievable DCG\\@K for the test data:\n",
    "$$\n",
    "NDCG@K = \\frac{DCG@K}{\\max DCG@K}\n",
    "$$\n",
    "\n",
    "    Unlike the other metrics, NDCG can handle data which contains \"dislikes\" in the\n",
    "form of negative values. If there are no negative values in the test data, it will\n",
    "be bounded between zero and one.\n",
    "\n",
    "* **Hit\\@K** (from which \"Hit Rate\" is calculated): this is a simpler yes/no metric\n",
    "that looks at whether any of the top-K recommended items were in the test set for\n",
    "a given user:\n",
    "$$\n",
    "Hit@K = \\max_{i=1..K}\n",
    "\\begin{cases}\n",
    "    1, & r_i \\in \\mathcal{T}\\\\\n",
    "    0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "The average of this metric across users is typically called \"Hit Rate\".\n",
    "\n",
    "* **RR\\@K** (\"reciprocal rank at k\", from which \"MRR\" or \"mean reciprocal rank\"\n",
    "is calculated):\n",
    "this metric only looks at the rank of the first recommended item that is in the test set,\n",
    "and outputs its inverse:\n",
    "$$\n",
    "RR@K = \\max_{i=1..K} \\frac{1}{i} \\:\\:\\:\\text{s.t.}\\:\\:\\: r_i \\in \\mathcal{T}\n",
    "$$\n",
    "The average of this metric across users is typically called \"Mean Reciprocal Rank\".\n",
    "\n",
    "* **ROC AUC** (\"area under the receiver-operating characteristic curve\"): see the\n",
    "[Wikipedia entry](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n",
    "for details. While the metrics above only looked at the top-K\n",
    "recommended items, this metric looks at the full ranking of items instead, and\n",
    "produces a standardized number between zero and one in which 0.5 denotes random\n",
    "predictions.\n",
    "\n",
    "* **PR AUC** (\"area under the precision-recall curve\"): while ROC AUC provides an\n",
    "overview of the overall ranking, one is typically only interested in how well it\n",
    "retrieves test items within top ranks, and for this the area under the\n",
    "precision-recall curve can do a better job at judging rankings, albeit the metric\n",
    "itself is not standardized and its minimum does not go as low as zero.\n",
    "\n",
    "    The metric is calculated using the fast but not-so-precise rectangular method,\n",
    "whose formula corresponds to the AP\\@K metric with K=N. Some papers and libraries\n",
    "call this the average of this metric the \"MAP\" or \"Mean Average Precision\" instead\n",
    "(without the \"\\@K\").\n",
    "\n",
    "_(For more details about the metrics, see the [package documentation](https://recometrics.readthedocs.io))_\n",
    "\n",
    "**NOT** covered by this package:\n",
    "\n",
    "* Metrics that look at the rareness of the items recommended (to evaluate so-called\n",
    "\"serendipity\").\n",
    "\n",
    "* Metrics that look at \"discoverability\".\n",
    "\n",
    "* Metrics that take into account the diversity of the ranked lists.\n",
    "\n",
    "** *\n",
    "\n",
    "Now a practical example with the [LastFM-360K](http://ocelma.net/MusicRecommendationDataset/lastfm-360K.html) dataset, which contains the number of times that different users played different songs from the Last.FM service.\n",
    "\n",
    "\n",
    "The example will compare different models from two popular libraries for recommender systems: [implicit](https://github.com/benfred/implicit) and [lightfm](https://github.com/lyst/lightfm). This library (`recosystem`) is able to work with any other library that would produce user and item embeddings, but for speed purposes the comparison will be limited to those two, as other popular libraries such as e.g. `spotlight` or `cornac` can be a few orders of magnitude slower in large datasets.\n",
    "\n",
    "For better results, one might want to apply transformations to these counts before fitting ALS models, such as taking logarithms and/or dividing the counts by some larger number, but for simplicity purposes, this notebook will use them as-is.\n",
    "\n",
    "#### Loading the data\n",
    "\n",
    "Loading the data and converting the triplets to sparse matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>3bd73256-3905-4f3a-97e2-8b341527f805</td>\n",
       "      <td>betty blowtorch</td>\n",
       "      <td>2137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>f2fb0ff0-5679-42ec-a55c-15109ce6e320</td>\n",
       "      <td>die Ärzte</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>b3ae82c2-e60b-4551-a76d-6620f1b456aa</td>\n",
       "      <td>melissa etheridge</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     UserId  \\\n",
       "0  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "1  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "2  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "\n",
       "                                 ItemId             Artist  Count  \n",
       "0  3bd73256-3905-4f3a-97e2-8b341527f805    betty blowtorch   2137  \n",
       "1  f2fb0ff0-5679-42ec-a55c-15109ce6e320          die Ärzte   1099  \n",
       "2  b3ae82c2-e60b-4551-a76d-6620f1b456aa  melissa etheridge    897  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "lfm = pd.read_table('usersha1-artmbid-artname-plays.tsv',\n",
    "                    sep='\\t', header=None,\n",
    "                    names=['UserId','ItemId', 'Artist','Count'])\n",
    "lfm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37425</td>\n",
       "      <td>2137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>152039</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>112365</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  ItemId  Count\n",
       "0       0   37425   2137\n",
       "1       0  152039   1099\n",
       "2       0  112365    897"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfm = lfm.drop('Artist', axis=1)\n",
    "lfm = lfm.loc[(lfm.Count > 0) & (lfm.UserId.notnull()) & (lfm.ItemId.notnull())]\n",
    "lfm['UserId'] = pd.Categorical(lfm.UserId).codes\n",
    "lfm['ItemId'] = pd.Categorical(lfm.ItemId).codes\n",
    "lfm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<358858x160112 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 17309518 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = coo_matrix((lfm.Count, (lfm.UserId, lfm.ItemId)))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a train-test split\n",
    "\n",
    "Now leaving aside a random sample of 10,000 users for model evaluation, for whom 30%\n",
    "of the data will be left as a hold-out test set.\n",
    "\n",
    "**Important:** `recometrics` can produce train-test splits that are intended to work in 2 possible ways:\n",
    "\n",
    "1. Selecting a sample of test users, then for each of those users selecting train and test items for each, while fitting the model **to the remainder of the users**, and then using that fitted model on the train data for these test users to produce new factors.\n",
    "2. Selecting a sample of test users, then for each of those users selecting train and test items for each, while fitting the model **to the remainder of the users PLUS the training data of the test users**, and using the obtained user factors directly.\n",
    "\n",
    "The first approach is more representative of real model usage and it is recommended to follow, but many popular Python libraries for recommender systems lack the functionality for calculating new user factors after the model is already fitted (for example, packages `implicit` and `cmfrec` have such functionality, but packages `cornac` and `lightfm` do not).\n",
    "\n",
    "As this notebook compares different libraries, it follows instead the second approach, despite not being ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x160112 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 145025 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import recometrics\n",
    "\n",
    "X_train, X_test, users_test = \\\n",
    "    recometrics.split_reco_train_test(\n",
    "        X, split_type=\"joined\",\n",
    "        users_test_fraction = None,\n",
    "        max_test_users = 10000,\n",
    "        items_test_fraction = 0.3\n",
    "    )\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establishing baselines\n",
    "\n",
    "In order to determine if a personalized recommendation model is bringing value or not,\n",
    "it's logical to compare such model against the simplest possible ways of making\n",
    "recommendations, such as:\n",
    "\n",
    "* Making random predictions.\n",
    "* Always predicting the same score for each item regardless of the\n",
    "user (non-personalized).\n",
    "\n",
    "This section creates such baselines to compare against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00146918, 0.01384678, 0.00019502, ..., 0.07879574, 0.00048185,\n",
       "       0.00015602])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cmfrec import MostPopular\n",
    "\n",
    "### Random recommendations (random latent factors)\n",
    "rng = np.random.default_rng(seed=1)\n",
    "UserFactors_random = rng.standard_normal(size=(X_test.shape[0], 5))\n",
    "ItemFactors_random = rng.standard_normal(size=(X_test.shape[1], 5))\n",
    "\n",
    "### Non-personalized recommendations\n",
    "model_baseline = MostPopular(implicit=True, user_bias=False).fit(X_train.tocoo())\n",
    "item_biases = model_baseline.item_bias_\n",
    "item_biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting models\n",
    "\n",
    "This section will fit two models from different software libraries that are based on different optimization criteria:\n",
    "\n",
    "* The typical implicit-feedback matrix factorization model described at the beginning,\n",
    "which considers all the entries in the matrix as zero or one with weights, minimizing\n",
    "squared error across all of them. This is known as the \"weighted regularized\n",
    "matrix factorization\" (WRMF) model or the implicit-ALS (\"iALS\") model.\n",
    "* The \"Bayesian Personalized Ranking\" model, which instead sub-samples negative items (user-item interactions that have not been observed) and minimizes an optimization objective that approximates the goodness of the relative ranking of positive/negative items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e481a386e76a4b56acf8ef89f40f87e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f2a02c68f90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from implicit.als import AlternatingLeastSquares\n",
    "from lightfm import LightFM\n",
    "\n",
    "### Fitting WRMF model\n",
    "wrmf = AlternatingLeastSquares(factors=50, regularization=1, random_state=123)\n",
    "wrmf.fit(X_train.T)\n",
    "\n",
    "### Fitting BPR model with WARP loss\n",
    "bpr_warp = LightFM(no_components=50, loss=\"warp\", random_state=123)\n",
    "bpr_warp.fit(X_train.tocoo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating metrics\n",
    "\n",
    "Finally, calculating recommendation quality metrics for all these models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5 ## Top-K recommendations to evaluate\n",
    "\n",
    "metrics_random = recometrics.calc_reco_metrics(\n",
    "    X_train[:X_test.shape[0]], X_test,\n",
    "    UserFactors_random, ItemFactors_random,\n",
    "    k=k, all_metrics=True\n",
    ")\n",
    "\n",
    "metrics_baseline = recometrics.calc_reco_metrics(\n",
    "    X_train[:X_test.shape[0]], X_test,\n",
    "    None, None, item_biases=item_biases,\n",
    "    k=k, all_metrics=True\n",
    ")\n",
    "\n",
    "metrics_wrmf = recometrics.calc_reco_metrics(\n",
    "    X_train[:X_test.shape[0]], X_test,\n",
    "    wrmf.user_factors[:X_test.shape[0]], wrmf.item_factors,\n",
    "    k=k, all_metrics=True\n",
    ")\n",
    "\n",
    "metrics_bpr_warp = recometrics.calc_reco_metrics(\n",
    "    X_train[:X_test.shape[0]], X_test,\n",
    "    bpr_warp.user_embeddings[:X_test.shape[0]], bpr_warp.item_embeddings,\n",
    "    item_biases=bpr_warp.item_biases,\n",
    "    k=k, all_metrics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These metrics are by default returned as a data frame, with each user representing\n",
    "a row and each metric a column - example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@5</th>\n",
       "      <th>TP@5</th>\n",
       "      <th>R@5</th>\n",
       "      <th>AP@5</th>\n",
       "      <th>TAP@5</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>Hit@5</th>\n",
       "      <th>RR@5</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>PR_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.973473</td>\n",
       "      <td>0.024638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.982510</td>\n",
       "      <td>0.009758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.531887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993460</td>\n",
       "      <td>0.132601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.746431</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.120256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972742</td>\n",
       "      <td>0.104456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   P@5  TP@5       R@5      AP@5  TAP@5    NDCG@5  Hit@5  RR@5   ROC_AUC  \\\n",
       "0  0.0   0.0  0.000000  0.000000    0.0  0.000000    0.0   0.0  0.973473   \n",
       "1  0.0   0.0  0.000000  0.000000    0.0  0.000000    0.0   0.0  0.982510   \n",
       "2  0.4   0.4  0.117647  0.117647    0.4  0.531887    1.0   1.0  0.993460   \n",
       "3  0.0   0.0  0.000000  0.000000    0.0  0.000000    0.0   0.0  0.746431   \n",
       "4  0.2   0.2  0.052632  0.052632    0.2  0.120256    1.0   1.0  0.972742   \n",
       "\n",
       "     PR_AUC  \n",
       "0  0.024638  \n",
       "1  0.009758  \n",
       "2  0.132601  \n",
       "3  0.000025  \n",
       "4  0.104456  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_baseline.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing models\n",
    "\n",
    "In order to compare models, one can instead summarize these metrics across users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P@5</th>\n",
       "      <th>TP@5</th>\n",
       "      <th>R@5</th>\n",
       "      <th>AP@5</th>\n",
       "      <th>TAP@5</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>Hit@5</th>\n",
       "      <th>RR@5</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>PR_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.500342</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-personalized</th>\n",
       "      <td>0.060460</td>\n",
       "      <td>0.060460</td>\n",
       "      <td>0.020657</td>\n",
       "      <td>0.012332</td>\n",
       "      <td>0.036260</td>\n",
       "      <td>0.044705</td>\n",
       "      <td>0.2427</td>\n",
       "      <td>0.141675</td>\n",
       "      <td>0.952542</td>\n",
       "      <td>0.029760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WRMF (a.k.a. iALS)</th>\n",
       "      <td>0.203315</td>\n",
       "      <td>0.203400</td>\n",
       "      <td>0.070627</td>\n",
       "      <td>0.046426</td>\n",
       "      <td>0.133956</td>\n",
       "      <td>0.157362</td>\n",
       "      <td>0.6253</td>\n",
       "      <td>0.393243</td>\n",
       "      <td>0.979968</td>\n",
       "      <td>0.121282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPR-WARP</th>\n",
       "      <td>0.134119</td>\n",
       "      <td>0.134209</td>\n",
       "      <td>0.046116</td>\n",
       "      <td>0.028627</td>\n",
       "      <td>0.083706</td>\n",
       "      <td>0.100951</td>\n",
       "      <td>0.4784</td>\n",
       "      <td>0.288444</td>\n",
       "      <td>0.977534</td>\n",
       "      <td>0.072259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         P@5      TP@5       R@5      AP@5     TAP@5  \\\n",
       "Random              0.000040  0.000040  0.000014  0.000009  0.000025   \n",
       "Non-personalized    0.060460  0.060460  0.020657  0.012332  0.036260   \n",
       "WRMF (a.k.a. iALS)  0.203315  0.203400  0.070627  0.046426  0.133956   \n",
       "BPR-WARP            0.134119  0.134209  0.046116  0.028627  0.083706   \n",
       "\n",
       "                      NDCG@5   Hit@5      RR@5   ROC_AUC    PR_AUC  \n",
       "Random              0.000009  0.0002  0.000125  0.500342  0.000158  \n",
       "Non-personalized    0.044705  0.2427  0.141675  0.952542  0.029760  \n",
       "WRMF (a.k.a. iALS)  0.157362  0.6253  0.393243  0.979968  0.121282  \n",
       "BPR-WARP            0.100951  0.4784  0.288444  0.977534  0.072259  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics = [\n",
    "    metrics_random,\n",
    "    metrics_baseline,\n",
    "    metrics_wrmf,\n",
    "    metrics_bpr_warp\n",
    "]\n",
    "all_metrics = pd.concat([m.mean(axis=0).to_frame().T for m in all_metrics], axis=0)\n",
    "all_metrics.index = [\n",
    "    \"Random\",\n",
    "    \"Non-personalized\",\n",
    "    \"WRMF (a.k.a. iALS)\",\n",
    "    \"BPR-WARP\"\n",
    "]\n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these metrics, the better-performing model under every criteria seems to be the WRMF model (weighted regularized matrix factorization , a.k.a. implicit-ALS) from the package `implicit`, achieving significantly better results than non-personalized recommendations and than the BPR (Bayesian Personalized Ranking) model with WARP loss from the `lightfm` package."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
